{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end model agent 를 사용하여 성능을 평가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능한 모델 class : Sequicity, DAMD, <strong>Neural Pipeline</strong>\n",
    "\n",
    "E2E model path : convlab2/e2e/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. E2E model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/donghoon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from convlab2.e2e.Transformer import Transformer\n",
    "from convlab2.e2e.sequicity.multiwoz import Sequicity\n",
    "from convlab2.e2e.damd.multiwoz import Damd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.modeling_utils:loading configuration file ./models/v1/config.json\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.modeling_utils:Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"token_ids\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"vocab_size\": 50281\n",
      "}\n",
      "\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.modeling_utils:loading weights file ./models/v1/pytorch_model.bin\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Model name './models/v1' not found in model shortcut name list (gpt2, gpt2-medium). Assuming './models/v1' is a path or url to a directory containing tokenizer files.\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Didn't find file ./models/v1/added_tokens.json. We won't load it.\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Didn't find file ./models/v1/special_tokens_map.json. We won't load it.\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:loading file None\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:loading file None\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:loading file ./models/v1/vocab.json\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:loading file ./models/v1/merges.txt\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <bos> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <eos> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <user> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <system> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <cs> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <dp> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <pad> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <dc> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding <nm> to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [restaurant_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [restaurant_reference] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [restaurant_postcode] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [hotel_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [hotel_reference] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [hotel_postcode] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [attraction_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [attraction_postcode] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [train_reference] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [train_id] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [taxi_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [hospital_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [hospital_postcode] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [police_phone] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Adding [police_postcode] to the vocabulary\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <bos> to the <bos> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <eos> to the <eos> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <user> to the <user> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <system> to the <system> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <cs> to the <cs> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <dp> to the <dp> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <pad> to the <pad> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <dc> to the <dc> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning <nm> to the <nm> key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [restaurant_phone] to the [restaurant_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [restaurant_reference] to the [restaurant_reference] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [restaurant_postcode] to the [restaurant_postcode] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [hotel_phone] to the [hotel_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [hotel_reference] to the [hotel_reference] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [hotel_postcode] to the [hotel_postcode] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [attraction_phone] to the [attraction_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [attraction_postcode] to the [attraction_postcode] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [train_reference] to the [train_reference] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [train_id] to the [train_id] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [taxi_phone] to the [taxi_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [hospital_phone] to the [hospital_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [hospital_postcode] to the [hospital_postcode] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [police_phone] to the [police_phone] key of the tokenizer\n",
      "INFO:convlab2.e2e.Transformer.pytorch_transformers.tokenization_utils:Assigning [police_postcode] to the [police_postcode] key of the tokenizer\n"
     ]
    }
   ],
   "source": [
    "# sys_agent = Sequicity()\n",
    "# sys_agent = Damd()\n",
    "sys_agent = Transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interact with agent !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hi, i want to eat spanish food in south.\n",
      "current domain :  restaurant\n",
      "dialogue state : {'food': 'spanish', 'pricerange': '<nm>', 'name': '<nm>', 'area': 'south'}\n",
      "system action : restaurant nooffer food spanish area south\n",
      "kb : None\n",
      "sys:  There are no Spanish restaurants in the south.\n",
      ">>> how about north ?\n",
      "current domain :  restaurant\n",
      "dialogue state : {'food': 'north american', 'pricerange': '<nm>', 'name': '<nm>', 'area': '<nm> '}\n",
      "system action : restaurant request restaurant inform choice two food north american area centre\n",
      "kb : {'addr': 'Regent Street City Centre', 'area': 'centre', 'food': 'north american', 'id': '19209', 'introduction': 'gourmet burger kitchen has a trendy interior and, although a bit more expensive than the average high street burger joint, the delicious burgers and other dishes are huge and freshly prepared with large side orders to match. Catering for vegetarians is provided', 'location': [52.20103, 0.126023], 'name': 'gourmet burger kitchen', 'phone': '01223312598', 'post': 'cb21ab', 'pricerange': 'expensive', 'type': 'restaurant', 'ref': '00000099'}\n",
      "sys:  I have two restaurants serving north american food in the centre. Would you like me to recommend one for you?\n",
      ">>> not north american food. I want Spanish food.\n",
      "current domain :  restaurant\n",
      "dialogue state : {'food': 'spanish', 'pricerange': '<nm>', 'name': '<nm>', 'area': '<nm> '}\n",
      "system action : restaurant inform name la tasca food spanish area centre\n",
      "kb : {'addr': '14 -16 Bridge Street', 'area': 'centre', 'food': 'spanish', 'id': '12566', 'introduction': 'la tasca is a spanish tapas restaurant and bar offering over 30 tapas dishes', 'location': [52.20903, 0.1183], 'name': 'la tasca', 'phone': '01223464630', 'post': 'cb21uf', 'pricerange': 'moderate', 'type': 'restaurant', 'ref': '00000035'}\n",
      "sys:  La Tasca serves Spanish food in the centre area.\n",
      ">>> how about north area ?\n",
      "current domain :  restaurant\n",
      "dialogue state : {'food': 'north american', 'pricerange': '<nm>', 'name': '<nm>', 'area': '<nm> '}\n",
      "system action : booking inform none none restaurant inform name gourmet burger kitchen area centre\n",
      "kb : {'addr': 'Regent Street City Centre', 'area': 'centre', 'food': 'north american', 'id': '19209', 'introduction': 'gourmet burger kitchen has a trendy interior and, although a bit more expensive than the average high street burger joint, the delicious burgers and other dishes are huge and freshly prepared with large side orders to match. Catering for vegetarians is provided', 'location': [52.20103, 0.126023], 'name': 'gourmet burger kitchen', 'phone': '01223312598', 'post': 'cb21ab', 'pricerange': 'expensive', 'type': 'restaurant', 'ref': '00000099'}\n",
      "sys:  Gourmet Burger Kitchen is in the centre area, would you like me to book it for you?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-adfa394d9c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/convlab2/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/convlab2/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "sys_agent.init_session()\n",
    "while True:\n",
    "    raw_text = input(\">>> \")\n",
    "    while not raw_text:\n",
    "        print('not empty')\n",
    "        raw_text = input(\">>> \")\n",
    "    if raw_text == 'r':\n",
    "        sys_agent.init_session()\n",
    "        continue\n",
    "    out_text = sys_agent.response(raw_text)\n",
    "    print('sys: ', out_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate E2E agents !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_bert:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_transformers.modeling_xlnet:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n"
     ]
    }
   ],
   "source": [
    "from convlab2.evaluator.multiwoz_eval import MultiWozEvaluator\n",
    "from convlab2.dialog_agent import PipelineAgent, BiSession\n",
    "from convlab2.nlu.milu.multiwoz import MILU\n",
    "from convlab2.nlu.milu.multiwoz import MILU\n",
    "from convlab2.dst.rule.multiwoz import RuleDST\n",
    "from convlab2.policy.rule.multiwoz import RulePolicy\n",
    "from convlab2.nlg.template.multiwoz import TemplateNLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultiWozEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User simulator 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): convlab.blob.core.windows.net:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from https://convlab.blob.core.windows.net/convlab-2/milu_multiwoz_all_context.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://convlab.blob.core.windows.net:443 \"HEAD /convlab-2/milu_multiwoz_all_context.tar.gz HTTP/1.1\" 200 0\n",
      "INFO:allennlp.models.archival:loading archive file /home/donghoon/.convlab2/cache/adeae6e5151198de3b1634fcb630a0243cd2e098a75703260c4489c6e92a5f51.4fff038b1c36dbb489d93575f604cf72276b651ac6b370b5a48f8f67df2ed971\n",
      "INFO:allennlp.models.archival:extracting archive file /home/donghoon/.convlab2/cache/adeae6e5151198de3b1634fcb630a0243cd2e098a75703260c4489c6e92a5f51.4fff038b1c36dbb489d93575f604cf72276b651ac6b370b5a48f8f67df2ed971 to temp dir /tmp/tmpem_45dw5\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass milu of <class 'allennlp.models.model.Model'>\n",
      "INFO:allennlp.common.params:type = default\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>\n",
      "INFO:allennlp.data.vocabulary:Loading token dictionary from /tmp/tmpem_45dw5/vocabulary.\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.model.Model'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}, 'type': 'milu'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.type = milu\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'convlab2.nlu.milu.model.MILU'> from params {'attention': {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400}, 'attention_for_intent': False, 'attention_for_tag': False, 'context_for_intent': True, 'context_for_tag': False, 'dropout': 0.3, 'encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'}, 'include_start_end_transitions': False, 'intent_encoder': {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'}, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}, 'tokens': {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.type = basic\n",
      "INFO:allennlp.common.params:model.text_field_embedder.embedder_to_indexer_map = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.allow_unmatched_keys = False\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.type = character_encoding\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 16\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'} and extras set()\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128} and extras set()\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 16\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 128\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.token_characters.dropout = 0.0\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 50, 'trainable': True, 'type': 'embedding'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.type = embedding\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.num_embeddings = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.embedding_dim = 50\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.pretrained_file = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.projection_dim = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.trainable = True\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.padding_index = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.max_norm = None\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.tokens.sparse = False\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 178, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.encoder.type = lstm\n",
      "INFO:allennlp.common.params:model.encoder.batch_first = True\n",
      "INFO:allennlp.common.params:model.encoder.stateful = False\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "INFO:allennlp.common.params:model.encoder.bidirectional = True\n",
      "INFO:allennlp.common.params:model.encoder.dropout = 0.5\n",
      "INFO:allennlp.common.params:model.encoder.hidden_size = 200\n",
      "INFO:allennlp.common.params:model.encoder.input_size = 178\n",
      "INFO:allennlp.common.params:model.encoder.num_layers = 1\n",
      "INFO:allennlp.common.params:model.encoder.batch_first = True\n",
      "/home/donghoon/anaconda3/envs/convlab2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 400, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.intent_encoder.type = lstm\n",
      "INFO:allennlp.common.params:model.intent_encoder.batch_first = True\n",
      "INFO:allennlp.common.params:model.intent_encoder.stateful = False\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "INFO:allennlp.common.params:model.intent_encoder.bidirectional = True\n",
      "INFO:allennlp.common.params:model.intent_encoder.dropout = 0.5\n",
      "INFO:allennlp.common.params:model.intent_encoder.hidden_size = 200\n",
      "INFO:allennlp.common.params:model.intent_encoder.input_size = 400\n",
      "INFO:allennlp.common.params:model.intent_encoder.num_layers = 1\n",
      "INFO:allennlp.common.params:model.intent_encoder.batch_first = True\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.attention.attention.Attention'> from params {'matrix_dim': 400, 'type': 'bilinear', 'vector_dim': 400} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.attention.type = bilinear\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.attention.bilinear_attention.BilinearAttention'> from params {'matrix_dim': 400, 'vector_dim': 400} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.attention.vector_dim = 400\n",
      "INFO:allennlp.common.params:model.attention.matrix_dim = 400\n",
      "INFO:allennlp.common.params:model.attention.normalize = True\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>\n",
      "INFO:allennlp.common.params:model.context_for_intent = True\n",
      "INFO:allennlp.common.params:model.context_for_tag = False\n",
      "INFO:allennlp.common.params:model.attention_for_intent = False\n",
      "INFO:allennlp.common.params:model.attention_for_tag = False\n",
      "INFO:allennlp.common.params:model.sequence_label_namespace = labels\n",
      "INFO:allennlp.common.params:model.intent_label_namespace = intent_labels\n",
      "INFO:allennlp.common.params:model.label_encoding = BIO\n",
      "INFO:allennlp.common.params:model.include_start_end_transitions = False\n",
      "INFO:allennlp.common.params:model.crf_decoding = False\n",
      "INFO:allennlp.common.params:model.constrain_crf_decoding = None\n",
      "INFO:allennlp.common.params:model.focal_loss_gamma = None\n",
      "INFO:allennlp.common.params:model.nongeneral_intent_weight = 5.0\n",
      "INFO:allennlp.common.params:model.num_train_examples = None\n",
      "INFO:allennlp.common.params:model.calculate_span_f1 = None\n",
      "INFO:allennlp.common.params:model.dropout = 0.3\n",
      "INFO:allennlp.common.params:model.verbose_metrics = False\n",
      "INFO:allennlp.common.params:model.regularizer.0.1.type = l2\n",
      "INFO:allennlp.common.registrable:instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>\n",
      "INFO:allennlp.nn.initializers:Initializing parameters\n",
      "INFO:allennlp.nn.initializers:Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "INFO:allennlp.nn.initializers:   attention._bias\n",
      "INFO:allennlp.nn.initializers:   attention._weight_matrix\n",
      "INFO:allennlp.nn.initializers:   encoder._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   encoder._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   encoder._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   encoder._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   encoder._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   encoder._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   encoder._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   encoder._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   intent_encoder._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   intent_projection_layer.bias\n",
      "INFO:allennlp.nn.initializers:   intent_projection_layer.weight\n",
      "INFO:allennlp.nn.initializers:   tag_projection_layer._module.bias\n",
      "INFO:allennlp.nn.initializers:   tag_projection_layer._module.weight\n",
      "INFO:allennlp.nn.initializers:   text_field_embedder.token_embedder_token_characters._embedding._module.weight\n",
      "INFO:allennlp.nn.initializers:   text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias\n",
      "INFO:allennlp.nn.initializers:   text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight\n",
      "INFO:allennlp.nn.initializers:   text_field_embedder.token_embedder_tokens.weight\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'context_size': 3, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}, 'type': 'milu'} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.type = milu\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'convlab2.nlu.milu.dataset_reader.MILUDatasetReader'> from params {'context_size': 3, 'token_indexers': {'token_characters': {'min_padding_length': 3, 'type': 'characters'}, 'tokens': {'lowercase_tokens': True, 'type': 'single_id'}}} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.context_size = 3\n",
      "INFO:allennlp.common.params:dataset_reader.agent = None\n",
      "INFO:allennlp.common.params:dataset_reader.random_context_size = True\n",
      "INFO:allennlp.common.params:dataset_reader.token_delimiter = None\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'min_padding_length': 3, 'type': 'characters'} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.type = characters\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer from params {'min_padding_length': 3} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.namespace = token_characters\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.start_tokens = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.end_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.min_padding_length = 3\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.token_characters.token_min_padding_length = 0\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.type = single_id\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer from params {'lowercase_tokens': True} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.namespace = tokens\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.lowercase_tokens = True\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.start_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.end_tokens = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "INFO:allennlp.common.params:dataset_reader.lazy = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading goal model is done\n"
     ]
    }
   ],
   "source": [
    "# MILU\n",
    "user_nlu = MILU()\n",
    "# not use dst\n",
    "user_dst = None\n",
    "# rule policy\n",
    "user_policy = RulePolicy(character='usr')\n",
    "# template NLG\n",
    "user_nlg = TemplateNLG(is_user=True)\n",
    "# assemble\n",
    "user_agent = PipelineAgent(user_nlu, user_dst, user_policy, user_nlg, name='user')\n",
    "sess = BiSession(sys_agent=sys_agent, user_agent=user_agent, kb_query=None, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init goal:\n",
      "{'taxi': {'info': {'leaveAt': '10:45', 'departure': 'aylesbray lodge guest house', 'destination': 'darrys cookhouse and wine shop'}, 'reqt': {'car type': '?', 'phone': '?'}}}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Value not found in standard value set: [62829735589] (slot: phone domain: taxi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current domain :  taxi\n",
      "dialogue state : {'destination': 'darrys cookhouse and wine shop', 'departure': 'aylesbray lodge guest house arriveBy <nm> '}\n",
      "system action : taxi inform car yellow lexus phone [taxi_phone] \n",
      "kb : {'taxi_colors': 'yellow', 'taxi_types': 'audi', 'taxi_phone': '62829735589'}\n",
      "user: Yes please . I need a taxi to commute . I want to go to darrys cookhouse and wine shop . The taxi should depart from aylesbray lodge guest house. Okay I also need a taxi that will leave by 10:45 .\n",
      "sys: Ok I have booked you a yellow lexus with the contact number 62829735589 .\n",
      "\n",
      "current domain :  taxi\n",
      "dialogue state : {'destination': 'darrys cookhouse and wine shop', 'departure': 'aylesbray lodge guest house arriveBy <nm> '}\n",
      "system action : general bye none none\n",
      "kb : {'taxi_colors': 'white', 'taxi_types': 'toyota', 'taxi_phone': '21313467257'}\n",
      "user: I am all set . Have a nice day . Bye .\n",
      "sys: Thanks for contacting us and have a nice day.\n",
      "\n",
      "task success: 1\n",
      "book rate: None\n",
      "inform precision/recall/f1: (1.0, 1.0, 1.0)\n",
      "--------------------------------------------------\n",
      "final goal:\n",
      "{'taxi': {'info': {'leaveAt': '10:45', 'departure': 'aylesbray lodge guest house', 'destination': 'darrys cookhouse and wine shop'}, 'reqt': {'car type': 'yellow lexus', 'phone': '62829735589'}}}\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(r_seed):\n",
    "    random.seed(r_seed)\n",
    "    np.random.seed(r_seed)\n",
    "    torch.manual_seed(r_seed)\n",
    "\n",
    "set_seed(20200821)\n",
    "\n",
    "sys_response = ''\n",
    "sess.init_session()\n",
    "print('init goal:')\n",
    "print(sess.evaluator.goal)\n",
    "print('-'*50)\n",
    "for i in range(20):\n",
    "    sys_response, user_response, session_over, reward = sess.next_turn(sys_response)\n",
    "    print('user:', user_response)\n",
    "    print('sys:', sys_response)\n",
    "    print()\n",
    "    if session_over is True:\n",
    "        break\n",
    "print('task success:', sess.evaluator.task_success())\n",
    "print('book rate:', sess.evaluator.book_rate())\n",
    "print('inform precision/recall/f1:', sess.evaluator.inform_F1())\n",
    "print('-'*50)\n",
    "print('final goal:')\n",
    "print(sess.evaluator.goal)\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:convlab2] *",
   "language": "python",
   "name": "conda-env-convlab2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
